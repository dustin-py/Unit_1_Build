{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1S1Py8KFCspoBv734XBdzFtnHsuo21GDF",
      "authorship_tag": "ABX9TyOuHa/zG4TkbFbYMH07VqzJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dustin-py/Unit_1_Build/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWv4duFdHz_u",
        "colab_type": "text"
      },
      "source": [
        "Research Question: What are the general personality traits of different countries?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-QQwp-NkNN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install chart_studio\n",
        "import chart_studio\n",
        "username = 'dustinstri92'\n",
        "api_key = 'qy21PLTSJyVgkLYh4uI9'\n",
        "chart_studio.tools.set_credentials_file(username=username, api_key=api_key)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZNX_Oqmtrzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip the data set using bash:\n",
        "! \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# dont forget to add a link to get your dataset dumb dumb\n",
        "\n",
        "'''\n",
        "OTHER WISE THE CODE WONT RUN FOR THE TL AND THE YOU LOOK LIKE BIG DUMB DUMB \n",
        "'''\n",
        "\n",
        "# SO DONT BE A DUMB DUMB, DUMB DUMB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y63SGeR5T71I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import external libraries:\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from textblob import TextBlob\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_1samp,ttest_ind,chi2_contingency\n",
        "\n",
        "\n",
        "# Instantiate a dataframe by using pandas:\n",
        "df = pd.read_csv('/content/drive/My Drive/data-final.csv',sep='\\t')\n",
        "\n",
        "\n",
        "# Get rid of unnecessary columns, by instantiating a new dataframe so that we can \n",
        "# keep the original with out having to rerun the whole note book:\n",
        "big5 = df.drop(columns=['screenw','screenh','introelapse','endelapse',\n",
        "                        'lat_appx_lots_of_err','long_appx_lots_of_err']).copy()\n",
        "\n",
        "\n",
        "# A little further cleaning to remove the elapsed time spent on each question,\n",
        "# may refer back to those columns later, but for now they will be taken out:\n",
        "for attr in big5.columns:\n",
        "    if '_E' in attr:\n",
        "        big5.drop(columns=attr,inplace=True)\n",
        "\n",
        "\n",
        "# Now lets get rid of all the country values equal to 'NONE':    \n",
        "remove_none = big5.set_index('country')\n",
        "remove_none.drop(index='NONE',inplace=True)\n",
        "big5 = remove_none.reset_index()    \n",
        "# Only samples with 'IPC' == 1 in the big5 dataframe so that we know we don't\n",
        "# have repeat tests so that our sample stay valid.\n",
        "big5 = big5[big5['IPC']==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zau163jKRDBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate a dataframe of the 20 with the most test results:\n",
        "top_20_test_numbers = pd.DataFrame(big5.country.value_counts()[:20]).index\n",
        "top_20_test_numbers = pd.Series(top_20_test_numbers,name='country')\n",
        "top_20_test_numbers = pd.DataFrame(top_20_test_numbers)\n",
        "\n",
        "def question_result_means_by_country(dataframe):\n",
        "    '''\n",
        "    Obtain the means of the test results for each \n",
        "    country in the dataframe. \n",
        "    '''\n",
        "    df = pd.DataFrame()\n",
        "    for i in dataframe.columns:\n",
        "        s_list = []\n",
        "        x,y=1,11\n",
        "        while y <= 51:\n",
        "            s_list.append(dataframe[i].iloc[x:y].mean())\n",
        "            series = pd.Series(s_list)    \n",
        "            x,y=x+10,y+10\n",
        "        df[i] = series\n",
        "        s_list.clear()    \n",
        "    return df\n",
        "\n",
        "def countrys_dataframe(itr_df,dataframe):\n",
        "    '''\n",
        "    By iterating through a dataframe column\n",
        "    and using the unique values from the iterated column to\n",
        "    return a dataframe based on the new means data. \n",
        "    '''\n",
        "    df = pd.DataFrame()\n",
        "    for i in itr_df.country.unique():\n",
        "        new = dataframe[dataframe['country']==i].iloc[:,:51]\n",
        "        df[i] = new.iloc[1:].mean()\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjlITSPSuFKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate a data frame of result means by country \n",
        "# useing the function created earlier:\n",
        "countrys = countrys_dataframe(top_20_test_numbers,big5)        \n",
        "# drop NaN values from the rows:\n",
        "countrys = countrys.dropna(1)\n",
        "# instantiate a new dataframe after passing it through\n",
        "# the other function created earliear:\n",
        "countrys = question_result_means_by_country(countrys)\n",
        "# replace the numbered columns with the result section names:\n",
        "countrys = countrys.rename({0:'EXT',1:'EST',2:'AGR',3:'CSN',4:'OPN'})\n",
        "# reset the index in order to use the index values in a column:\n",
        "countrys = countrys.reset_index()\n",
        "countrys['section'] = countrys['index']\n",
        "countrys = countrys.drop('index',1)\n",
        "# display new cleaned dataframe:\n",
        "countrys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V78leY0iXVx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "countrys_t = countrys.T.reset_index()\n",
        "countrys_t['country'] = countrys_t['index']\n",
        "countrys_t = countrys_t.drop('index',1)\n",
        "countrys_t.rename(columns={0:'Extroversion',1:'Neuroticism',2:'Agreeability',3:'Conscientiousness',4:'Openness'}, inplace=True)\n",
        "c = countrys_t.iloc[:-1,:-1]\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaled_country_t = StandardScaler().fit_transform(c)\n",
        "scaled_country_t = pd.DataFrame(scaled_country_t,columns=c.columns)\n",
        "scaled_country_t['country'] = countrys_t.country[:-1]\n",
        "scaled_country_t"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9ywf74Y41Xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "color_list = [\n",
        "              'dodgerblue', 'grey', 'aqua', 'darkslateblue', 'darkslategrey',\n",
        "                'darkturquoise', 'darkviolet', 'orange', 'deeppink', 'blue',\n",
        "                'blueviolet', 'brown', 'burlywood', 'cadetblue',\n",
        "                'chartreuse', 'chocolate', 'coral', 'cornflowerblue','powderblue',\n",
        "              'seagreen'\n",
        "]\n",
        "\n",
        "# darkslateblue, darkslategray, darkslategrey,\n",
        "#                 darkturquoise, darkviolet, deeppink, dee\n",
        "\n",
        "layout = go.Layout(\n",
        "    paper_bgcolor='rgba(0,0,0,.7)',\n",
        "    plot_bgcolor='rgba(0,0,0)',\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=16,\n",
        "        color=\"White\"))\n",
        "\n",
        "fig = go.Figure(layout=layout,data=[\n",
        "    go.Bar(marker={'color':color_list},name=i, x=scaled_country_t.country, y=scaled_country_t[i]) for i in scaled_country_t.columns[:-1]\n",
        "])\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group')\n",
        "fig.show()\n",
        "\n",
        "# import chart_studio.plotly as py\n",
        "# apy.plot(fig, filename = 'big5_heatmap', auto_open=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm8NJOpWxqpo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb5DrjU_Uv_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f# Create a dictionary that holds the questions related to each of the columns, \n",
        "# because in this data we are using abbreviation based on the type of question.\n",
        "col_dic = {'EXT1'\t:\"I am the life of the party.\",\n",
        "           'EXT2'\t:\"I don't talk a lot.\",\n",
        "           'EXT3'\t:\"I feel comfortable around people.\",\n",
        "           'EXT4'\t:\"I keep in the background.\",\n",
        "           'EXT5'\t:\"I start conversations.\",\n",
        "           'EXT6'\t:\"I have little to say.\",\n",
        "           'EXT7'\t:\"I talk to a lot of different people at parties.\",\n",
        "           'EXT8'\t:\"I don't like to draw attention to myself.\",\n",
        "           'EXT9'\t:\"I don't mind being the center of attention.\",\n",
        "           'EXT10'\t:\"I am quiet around strangers.\",\n",
        "           'EST1'\t:\"I get stressed out easily.\",\n",
        "           'EST2'\t:\"I am relaxed most of the time.\",\n",
        "           'EST3'\t:\"I worry about things.\",\n",
        "           'EST4'\t:\"I seldom feel blue.\",\n",
        "           'EST5'\t:\"I am easily disturbed.\",\n",
        "           'EST6'\t:\"I get upset easily.\",\n",
        "           'EST7'\t:\"I change my mood a lot.\",\n",
        "           'EST8'\t:\"I have frequent mood swings.\",\n",
        "           'EST9'\t:\"I get irritated easily.\",\n",
        "           'EST10'\t:\"I often feel blue.\",\n",
        "           'AGR1'\t:\"I feel little concern for others.\",\n",
        "           'AGR2'\t:\"I am interested in people.\",\n",
        "           'AGR3'\t:\"I insult people.\",\n",
        "           'AGR4'\t:\"I sympathize with others' feelings.\",\n",
        "           'AGR5'\t:\"I am not interested in other people's problems.\",\n",
        "           'AGR6'\t:\"I have a soft heart.\",\n",
        "           'AGR7'\t:\"I am not really interested in others.\",\n",
        "           'AGR8'\t:\"I take time out for others.\",\n",
        "           'AGR9'\t:\"I feel others' emotions.\",\n",
        "           'AGR10'\t:\"I make people feel at ease.\",\n",
        "           'CSN1'\t:\"I am always prepared.\",\n",
        "           'CSN2'\t:\"I leave my belongings around.\",\n",
        "           'CSN3'\t:\"I pay attention to details.\",\n",
        "           'CSN4'\t:\"I make a mess of things.\",\n",
        "           'CSN5'\t:\"I get chores done right away.\",\n",
        "           'CSN6'\t:\"I often forget to put things back in their proper place.\",\n",
        "           'CSN7'\t:\"I like order.\",                                \n",
        "           'CSN8'\t:\"I shirk my duties.\",                                                   \n",
        "           'CSN9'\t:\"I follow a schedule.\",                                                   \n",
        "           'CSN10'\t:\"I am exacting in my work.\",\n",
        "           'OPN1'\t:\"I have a rich vocabulary.\",                                                \n",
        "           'OPN2'\t:\"I have difficulty understanding abstract ideas.\",                       \n",
        "           'OPN3'\t:\"I have a vivid imagination.\",                                             \n",
        "           'OPN4'\t:\"I am not interested in abstract ideas.\",                                \n",
        "           'OPN5'\t:\"I have excellent ideas.\",                                                 \n",
        "           'OPN6'\t:\"I do not have a good imagination.\",                                      \n",
        "           'OPN7'\t:\"I am quick to understand things.\",                                     \n",
        "           'OPN8'\t:\"I use difficult words.\",                                                  \n",
        "           'OPN9'\t:\"I spend time reflecting on things.\",                                 \n",
        "           'OPN10'\t:\"I am full of ideas.\"}          \n",
        "\n",
        "# Create lists of the sentemint analysis of each question/column then group them \n",
        "# based on that sentiment:\n",
        "def sentimentGrouping(dictionary):\n",
        "    '''\n",
        "    From a dictionary where the text are the values related to the keys, and\n",
        "    perform sentiment analysis on the test using TextBlob library.\n",
        "\n",
        "    Takes one parameter: dictionary={key:'value'}\n",
        "    '''\n",
        "    pos_obj = []\n",
        "    pos_subj = []\n",
        "    neg_obj = []\n",
        "    neg_subj = []\n",
        "    neutral = []\n",
        "    for item in dictionary:\n",
        "        blob = TextBlob(dictionary[item]).sentiment\n",
        "        # pos_obj:\n",
        "        if blob[0] > 0.0 and blob[1] <= 0.5:\n",
        "            pos_obj.append(item)\n",
        "        # pos_subj:\n",
        "        elif blob[0] > 0.0 and blob[1] >= 0.5:\n",
        "            pos_subj.append(item)\n",
        "        # neg_obj:\n",
        "        elif blob[0] < 0.0 and blob[1] <= 0.5:\n",
        "            neg_obj.append(item)\n",
        "        # neg_subj:\n",
        "        elif blob[0] < 0.0 and blob[1] >= 0.5:\n",
        "            neg_subj.append(item)\n",
        "        # neutral:\n",
        "        elif blob[0] == 0.0:\n",
        "            neutral.append(item)     \n",
        "    return pos_obj,pos_subj,neg_obj,neg_subj,neutral \n",
        "\n",
        "\n",
        "# use the sentiment grouping function created earlier in the notebook to create\n",
        "# lists of columns base on;\n",
        "'''\n",
        "   1. po = positive and objective\n",
        "   2. ps = positive and subjective\n",
        "   3. no = negative and objective\n",
        "   4. ns = negative and subjective\n",
        "   5. neu = neutral \n",
        "'''\n",
        "po,ps,no,ns,neu = sentimentGrouping(col_dic)\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate lists of the polarity of the sentiment of the question and \n",
        "# the subjectivity of the question:\n",
        "polarity = []\n",
        "subjectivity = []\n",
        "# words = []\n",
        "for text in col_dic:\n",
        "    blob = TextBlob(col_dic[text])\n",
        "    polarity.append(blob.sentiment[0])\n",
        "    subjectivity.append(blob.sentiment[1])\n",
        "    # words.append(blob.sentiment_assessments[2][0][0:3])\n",
        "\n",
        "\n",
        "# Sentiment data frame:                                          # USE THE FULL \n",
        "                                                                 # SENTIMENT \n",
        "                                                                 # ANALYSIS AND \n",
        "                                                                 # ADD THE \n",
        "                                                                 # SPECIFIC \n",
        "                                                                 # WORDS INTO \n",
        "                                                                 # THE CHARTS\n",
        "                                                                 # USING PLOTLY.\n",
        "sentiment_data = {'pol':polarity,'subj':subjectivity}  # ,'word':words\n",
        "sent_df = pd.DataFrame(sentiment_data)\n",
        "questions = []\n",
        "for n in range(10):\n",
        "    questions.append('ext')\n",
        "for n in range(10):\n",
        "    questions.append('est') \n",
        "for n in range(10):\n",
        "    questions.append('agr')\n",
        "for n in range(10):\n",
        "    questions.append('csn')\n",
        "for n in range(10):\n",
        "    questions.append('opn')      \n",
        "quest_ser = pd.Series(questions)                           \n",
        "sent_df['types'] = quest_ser.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q2myfL3CKPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "import chart_studio.plotly as py\n",
        "\n",
        "\n",
        "layout = go.Layout(\n",
        "    paper_bgcolor='rgba(0,0,0,.7)',\n",
        "    plot_bgcolor='white',\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=16,\n",
        "        color=\"White\")\n",
        ")\n",
        "\n",
        "fig = go.Figure(layout=layout)\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=sent_df['types'],\n",
        "    y=sent_df['pol'],\n",
        "    name='Sentiment Polarity',\n",
        "    marker_color='blue'\n",
        "))\n",
        "fig.add_trace(go.Bar(\n",
        "    x=sent_df['types'],\n",
        "    y=sent_df['subj'],\n",
        "    name='Sentiment Subjectivity',\n",
        "    marker_color='green'\n",
        "))\n",
        "\n",
        "# Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
        "fig.update_layout(barmode='group', xaxis_tickangle=-45)\n",
        "fig.show()\n",
        "py.plot(fig, filename = 'sentiment', auto_open=True)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# list of all neutral questions, maybe group them by sentiment                 #\n",
        "################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuu1RGnrm4qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add country abbvr chart"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvYPgq9o64n6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}